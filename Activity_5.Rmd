---
title: 'Activity 5: Intro into Data Visualization'
author: "Jacob Watts"
date: "10/9/2020"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Questions

# Question 1

Based on the location of the guage and the urban nature of the stream, I would think that the increasing urbanization would increase the peak flow in the stream and decrease the time between storms and the peak flow. This is due to the impermeability of asphalt and buildings associated with urbanization and deforestation. The notes on the guage indicate that some of the flow in the stream originates outside of the basin. During large, sustained storm systems, I would expect unexplainably large flow rates due to extra input from neighboring basins via drainage systems.

```{r, include = T}
# set working directory
setwd("~/R/GitHub/GEOG331")
#date management
library(lubridate)
# read in streamflow data
datH <- read.csv("stream_flow_data.csv",
                na.strings = c("Eqp"))
# look at data
head(datH)
# also precipitation data
#read in precipitation data
#hourly precipitation is in mm
datP <- read.csv("2049867.csv") 
# look at precipitation data
head(datP)
#only use most reliable measurements
# A means approved for publication
datD <- datH[datH$discharge.flag == "A",]


#### define time for streamflow #####
#convert date and time
datesD <- as.Date(datD$date, "%m/%d/%Y")
#get day of year
datD$doy <- yday(datesD)
#calculate year
datD$year <- year(datesD)
#define time
timesD <- hm(datD$time)

#### define time for precipitation #####    
dateP <- ymd_hm(datP$DATE)
#get day of year
datP$doy <- yday(dateP)
#get year 
datP$year <- year(dateP)

#### get decimal formats #####
#convert time from a string to a more usable format
#with a decimal hour
datD$hour <- hour(timesD ) + (minute(timesD )/60)
#get full decimal time
datD$decDay <- datD$doy + (datD$hour/24)
#calculate a decimal year, but account for leap year
datD$decYear <- ifelse(leap_year(datD$year),datD$year + (datD$decDay/366),
                        datD$year + (datD$decDay/365))
#calculate times for datP                       
datP$hour <- hour(dateP ) + (minute(dateP )/60)
#get full decimal time
datP$decDay <- datP$doy + (datP$hour/24)
#calculate a decimal year, but account for leap year
datP$decYear <- ifelse(leap_year(datP$year),datP$year + (datP$decDay/366),
                        datP$year + (datP$decDay/365))
```

# Question 2

The decimal year is calculated by creating a new vector of equal length by doing vector algebra: Dividing the decimal day by the number of days in the year, while using the logical definition ifelse function to define differences between the leap year and non-leap years.

# Question 3

```{r, include = T}
#plot discharge
plot(datD$decYear, datD$discharge, type="l", xlab="Year", ylab=expression(paste("Discharge ft"^"3 ","sec"^"-1")))
# hard to tell trends ihe data because there is so much data.
nrow(datD)
nrow(datP)

```

There are 393798 observations in the Discharge data and 16150 measurements in the precipitation data.

# Question 4

The expression function creates an expression object. The paste function in conjunction with the expression function allows one to combine the expression function with a label to get superscripted numbers and other mathematical symbols that normally don't work in R.

The main issue with using this notation in base R is that when the plot is resized, the text is treated as an image and it's dimensions are altered.

```{r, include = T}
#basic formatting
aveF <- aggregate(datD$discharge, by=list(datD$doy), FUN="mean")
colnames(aveF) <- c("doy","dailyAve")
sdF <- aggregate(datD$discharge, by=list(datD$doy), FUN="sd")
colnames(sdF) <- c("doy","dailySD")
#start new plot
dev.new(width=8,height=8)
#bigger margins
par(mai=c(1,1,1,1))
#make plot

plot(aveF$doy,aveF$dailyAve, 
    type="l", 
    xlab="Year", 
    ylab=expression(paste("Discharge ft"^"3 ","sec"^"-1")),
    lwd=2,
    ylim=c(0,90),
    xaxs="i", yaxs ="i",#remove gaps from axes
    axes=FALSE)#no axes
# add standard deviation
polygon(c(aveF$doy, rev(aveF$doy)),#x coordinates
        c(aveF$dailyAve-sdF$dailySD,rev(aveF$dailyAve+sdF$dailySD)),#ycoord
        col=rgb(0.392, 0.584, 0.929,.2), #color that is semi-transparent
        border=NA#no border
        )     
# change default axes
axis(1, seq(0,360, by=40), #tick intervals
        lab=seq(0,360, by=40)) #tick labels
axis(2, seq(0,80, by=20),
        seq(0,80, by=20),
        las = 2)#show ticks at 90 degree angle
# Add a legend
legend("topright", c("mean","1 standard deviation"), #legend items
                lwd=c(2,NA),#lines
                col=c("black",rgb(0.392, 0.584, 0.929,.2)),#colors
                pch=c(NA,15),#symbols
                 bty="n")#no legend border

```

# Question 5

```{r, include = T}
# adding in measurements from 2017
nextyear <- dplyr::filter(datD, year == 2017)
# aggregate
ave2017 <- aggregate(nextyear$discharge, by=list(nextyear$doy), FUN="mean")
colnames(ave2017) <- c("doy","dailyAve")
sd2017 <- aggregate(nextyear$discharge, by=list(nextyear$doy), FUN="sd")
colnames(sd2017) <- c("doy","dailySD")

#start new plot
dev.new(width=8,height=8)
#bigger margins
par(mai=c(1,1,1,1))
#make plot
plot(aveF$doy, aveF$dailyAve, 
    type="l", 
    xlab="Day of Year", 
    ylab=expression(paste("Discharge ft"^"3 ","sec"^"-1")),
    lwd=2,
    ylim=c(0,90),
    xlim=c(0,366),
    xaxs="i", yaxs ="i",#remove gaps from axes
    axes=FALSE)#no axes
# add standard deviation
polygon(c(aveF$doy, rev(aveF$doy)),#x coordinates
        c(aveF$dailyAve-sdF$dailySD,rev(aveF$dailyAve+sdF$dailySD)),#ycoord
        col=rgb(0.392, 0.584, 0.929,.2), #color that is semi-transparent
        border=NA#no border
        )
# add 2017 data
lines(ave2017$doy, ave2017$dailyAve,
    lwd=2, col = "red")
# add standard errors
polygon(c(ave2017$doy, rev(ave2017$doy)),#x coordinates
        c(ave2017$dailyAve-sd2017$dailySD,rev(ave2017$dailyAve+sd2017$dailySD)),#ycoord
        col=rgb(0.255,0.020,0.147,.5), #color that is semi-transparent
        border=NA#no border
        )
# change default axes
axis(1, seq(15,365, by=(365/12)), #tick intervals
        lab=c(month.abb))#tick labels
abline(h=0)
axis(2, seq(0,80, by=20),
        seq(0,80, by=20),
        las = 2)#show ticks at 90 degree angle
# Add a legend
legend("topright", c("mean","1 standard deviation", "1 sd 2017"), #legend items
                lwd=c(2,NA, NA),#lines
                col=c("black",rgb(0.392, 0.584, 0.929,.2), rgb(0.255,0.020,0.147,.5)),#colors
                pch=c(NA,15, 15),#symbols
                 bty="n")#no legend border
```

# Question 6

In 2017, the rainiest season is around 90 days after January first, with lots of stream discharge occuring during that time. Stream discharge begins to deminish after that (with short bouts of increased rainfall) to a low around 270 days after January first. A final increased discharge event of the season occurs at about 300 days after January first. Median and quartiles might be a better representation of discharge, because it would better capture actual measurements instead of calculated values from the entire day of measurement. This median and quartiles are also less influenced by extreme values.

# Question 7
Create a dataframe that indicates what days have a full 24 hours of precipitation measurements. Make a plot of all discharge measurements and symbolize the days that have all precipitation measurements available.

```{r, include = T}
head(datP)
# make a new column with unique day.
datP$yeardate <- paste(datP$doy, datP$year)

# make into factor
datP$yeardate <- as.factor(datP$yeardate)
# make a new column with the sum of the "hours"
datP <- merge(datP,aggregate(datP$hour,list(datP$yeardate),sum),
     by.x="yeardate", 
     by.y="Group.1")

names(datP)[11] <- "sum.hour"
# make a final column that says if the day is complete or not assuming that 24+23+22+21 etc equals 276
datP$complete <- ifelse(datP$sum.hour == 276, "complete", "incomplete")
head(datP)
head(datD)
datPD <- left_join(datD, datP)

# make complete into a factor
datPD$complete <- as.factor(datPD$complete)
unique(datPD$complete)
# make plot
library(ggpubr)
ggplot(datPD, aes(decYear, discharge, by = complete, color = complete)) + geom_line() +
    xlab("Year") +
    ylab(expression(paste("Discharge ft"^"3 ","sec"^"-1"))) + theme_pubr()

```




# Question 8

```{r, include = T}
#subsest discharge and precipitation within range of interest
hydroD <- datD[datD$doy >= 248 & datD$doy < 250 & datD$year == 2011,]
hydroP <- datP[datP$doy >= 248 & datP$doy < 250 & datP$year == 2011,]
min(hydroD$discharge)

#get minimum and maximum range of discharge to plot
#go outside of the range so that it's easy to see high/low values
#floor rounds down the integer
yl <- floor(min(hydroD$discharge))-1
#ceiling rounds up to the integer
yh <- ceiling(max(hydroD$discharge))+1
#minimum and maximum range of precipitation to plot
pl <- 0
pm <-  ceiling(max(hydroP$HPCP))+.5
#scale precipitation to fit on the 
hydroP$pscale <- (((yh-yl)/(pm-pl)) * hydroP$HPCP) + yl

par(mai=c(1,1,1,1))
#make plot of discharge
plot(hydroD$decDay,
    hydroD$discharge, 
    type="l", 
    ylim=c(yl,yh), 
    lwd=2,
    xlab="Day of year", 
    ylab=expression(paste("Discharge ft"^"3 ","sec"^"-1")))
#add bars to indicate precipitation 
for(i in 1:nrow(hydroP)){ polygon(c(hydroP$decDay[i]-0.017,hydroP$decDay[i]-0.017,
            hydroP$decDay[i]+0.017,hydroP$decDay[i]+0.017),
        c(yl,hydroP$pscale[i],hydroP$pscale[i],yl),
        col=rgb(0.392, 0.584, 0.929,.2), border=NA)
}

##### Second Hydrograph #####
# define only winter
Pchoose <- datP[datP$doy <= 100,]
# look through data frame for complete records in winter.
hydroD2 <- datD[datD$doy >= 32 & datD$doy <= 33 & datD$year == 2008,]
hydroP2 <- datP[datP$doy >= 32 & datP$doy <= 33 & datP$year == 2008,]

# minimum values
yl <- floor(min(hydroD2$discharge))-1
#ceiling rounds up to the integer
yh <- ceiling(max(hydroD2$discharge))+1
#minimum and maximum range of precipitation to plot
pl <- 0
pm <-  ceiling(max(hydroP2$HPCP))+.5
#scale precipitation to fit on the 
hydroP2$pscale <- (((yh-yl)/(pm-pl)) * hydroP2$HPCP) + yl

par(mai=c(1,1,1,1))
#make plot of discharge
plot(hydroD2$decDay,
    hydroD2$discharge, 
    type="l", 
    ylim=c(yl,yh), 
    lwd=2,
    xlab="Day of year", 
    ylab=expression(paste("Discharge ft"^"3 ","sec"^"-1")))
#add bars to indicate precipitation 
for(i in 1:nrow(hydroP2)){ polygon(c(hydroP2$decDay[i]-0.017,hydroP2$decDay[i]-0.017,
            hydroP2$decDay[i]+0.017,hydroP2$decDay[i]+0.017),
        c(yl,hydroP2$pscale[i],hydroP2$pscale[i],yl),
        col=rgb(0.392, 0.584, 0.929,.2), border=NA)
}
```

I chose this day by making a new dataframe called Pchoose which was all years and days less than 100, January to early April, when precipitation is likely to fall as snow. I then searched for days with a non-zero precipitation record and most hourly records available by scrolling through the dataframe. The few that are missing from this dataframe were checked using methods used in Activity 3. I seaerched manually rather than filtering the dataframe, because I needed to see if the 0.00 values were also available for the precipitation event of choice. The first grap has three peaks in precipitation and three subsequent peaks in stream discharge, while the second graph has a two peaks in precipitation, but only a single peak in stream discharge, which suggests that the precipitation event started as rain and transitioned to snow. However, no temperature data is available so this is hard to determine. Also this peak is much larger than the summer peak, which may be due to increased snowmelt upon precipitation.

With only hourly precipitation, it is hard to know the exact time delay between precipitation and increased discharge. Spikes in a hydrograph could occur without rain during snowmelt events like a hot sunny, spring day.

# Question 9

```{r, include = T}
#specify year as a factor
datD$yearPlot <- as.factor(datD$year)

# subset just 2016 and 2017
datD1617 <- datD[xor(datD$year == 2016, datD$year == 2017),]

# create a season factor

datD1617$season <- ifelse(datD1617$doy >= 60 & datD1617$doy <= 121, "Spring",
        ifelse(datD1617$doy >= 122 & datD1617$doy <= 243, "Summer",
        ifelse(datD1617$doy >= 244 & datD1617$doy <= 334, "Fall",
        ifelse(xor(datD1617$doy >= 335, datD1617$doy <= 59), "Winter",
                        NA  ))))
datD1617$Year <- datD1617$yearPlot
library(ggpubr)
datD1617$season <- as.factor(datD1617$season)
ggplot(data= datD1617, aes(season, discharge, by = Year, color = Year)) + 
    geom_violin(lwd = 1) +
    theme_pubr() +
       xlab("Season") +
       ylab(expression(paste("Discharge ft"^"3 ","sec"^"-1")))
```

Across both year, spring has a higher discharge on average because of snow melt from the winter, and summer has the lowest discharge across both years because of evaporation and transpiration. Fall and winter and intermediate. There are no obvious trends in the data between the years except that some of the outliers are much higher in one year versus the other. For example, in 2017, the discharge reached much higher outlier values than it did in the spring. A lot of seasons seem to have a bimodel distribution of discharge values, the lower of which is likely associated with base flow and the higher associated with rainfall events.

# Question 10

https://github.com/jlwatts98/GEOG331/blob/master/Activity_5.Rmd

